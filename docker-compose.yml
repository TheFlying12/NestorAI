services:
    openclaw:
      container_name: openclaw
      image: ghcr.io/openclaw/openclaw:latest
      restart: unless-stopped
      depends_on:
        ollama:
          condition: service_healthy
        ollama_init:
          condition: service_completed_successfully
      healthcheck:
        test: ["CMD", "node", "-e", "fetch('http://localhost:18789/').then(r=>process.exit(r.ok?0:1)).catch(()=>process.exit(1))"]
        interval: 10s
        timeout: 5s
        retries: 12
        start_period: 30s
      environment:
        OPENCLAW_MODE: local
        OPENCLAW_LLM_PROVIDER: ${OPENCLAW_LLM_PROVIDER:-ollama}
        OPENCLAW_LLM_BASE_URL: http://ollama:11434
        OPENCLAW_LLM_MODEL: ${OPENCLAW_LLM_MODEL:-llama3.2:1b-instruct-q4_K_M}
        OLLAMA_API_KEY: ${OLLAMA_API_KEY:-ollama-local}
        OPENAI_API_KEY: ${OPENAI_API_KEY}
        GEMINI_API_KEY: ${GEMINI_API_KEY}
        OPENCLAW_DATA_DIR: /data
        OPENCLAW_STATE_DIR: /data
        OPENCLAW_LOG_LEVEL: INFO
        OPENCLAW_GATEWAY_TOKEN: ${OPENCLAW_GATEWAY_TOKEN}
      command: ["node","openclaw.mjs","gateway","--allow-unconfigured","--bind","lan","--port","18789"]
      ports: 
        - "18789:18789"
      volumes:
        - openclaw_data:/data
        - ./skills:/data/skills:ro
      networks:
        - local_ai_net

    ollama:
      image: ollama/ollama:latest
      container_name: ollama
      restart: unless-stopped
      environment:
        OLLAMA_HOST: 0.0.0.0
      volumes:
        - ollama_data:/root/.ollama
      networks:
        - local_ai_net
      ports:
        - "11434:11434"
      healthcheck:
        test: ["CMD", "ollama", "list"]
        interval: 15s
        timeout: 10s
        retries: 10
        start_period: 20s

    ollama_init:
      image: curlimages/curl:latest
      container_name: ollama-init
      depends_on:
        ollama:
          condition: service_healthy
      restart: "no"
      command:
        [
          "-sS",
          "-X",
          "POST",
          "http://ollama:11434/api/pull",
          "-H",
          "Content-Type: application/json",
          "-d",
          "{\"name\":\"${OPENCLAW_LLM_MODEL:-llama3.2:1b-instruct-q4_K_M}\"}"
        ]
      networks:
        - local_ai_net

    gateway:
      build:
        context: ./gateway_service
      container_name: gateway-service
      restart: unless-stopped
      depends_on:
        openclaw:
          condition: service_healthy
      environment:
        APP_ENV: production
        LOG_LEVEL: INFO
        PROVIDER: ${PROVIDER:-telegram}
        TELEGRAM_BOT_TOKEN: ${TELEGRAM_BOT_TOKEN}
        TELEGRAM_WEBHOOK_SECRET: ${TELEGRAM_WEBHOOK_SECRET}
        TELEGRAM_WEBHOOK_URL: ${TELEGRAM_WEBHOOK_URL}
        OPENCLAW_URL: http://openclaw:18789
        OPENCLAW_ROUTE: ${OPENCLAW_ROUTE:-/v1/chat/completions}
        OPENCLAW_MODEL: ${OPENCLAW_MODEL:-openclaw}
        OPENCLAW_GATEWAY_TOKEN: ${OPENCLAW_GATEWAY_TOKEN}
        DB_PATH: /data/gateway.db
        RAM_WARN_THRESHOLD_GB: ${RAM_WARN_THRESHOLD_GB:-2.0}
        VRAM_WARN_MB: ${VRAM_WARN_MB:-2048}
        DISPATCH_MAX_RETRIES: ${DISPATCH_MAX_RETRIES:-1}
        DISPATCH_TIMEOUT_SECONDS: ${DISPATCH_TIMEOUT_SECONDS:-180}
        CONTEXT_WINDOW_TURNS: ${CONTEXT_WINDOW_TURNS:-12}
        SUMMARY_UPDATE_EVERY_TURNS: ${SUMMARY_UPDATE_EVERY_TURNS:-6}
        SUMMARY_TOKEN_THRESHOLD: ${SUMMARY_TOKEN_THRESHOLD:-3500}
        SUMMARY_MAX_CHARS: ${SUMMARY_MAX_CHARS:-1200}
        SUMMARY_TIMEOUT_SECONDS: ${SUMMARY_TIMEOUT_SECONDS:-30}
        ENABLE_CONTEXT_SUMMARY: ${ENABLE_CONTEXT_SUMMARY:-true}
        MESSAGE_RETENTION_DAYS: ${MESSAGE_RETENTION_DAYS:-90}
        RETENTION_INTERVAL_SECONDS: ${RETENTION_INTERVAL_SECONDS:-86400}
      volumes:
        - gateway_data:/data
      networks:
        - local_ai_net
      ports:
        - "9000:9000"

networks:
  local_ai_net:
    driver: bridge

volumes:
  openclaw_data:
  ollama_data:
  gateway_data:
